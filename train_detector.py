# FootAndBall: Integrated Player and Ball Detector
# Jacek Komorowski, Grzegorz Kurzejamski, Grzegorz Sarwas
# Copyright (c) 2020 Sport Algorithmics and Gaming

#
# Train FootAndBall detector on ISSIA-CNR Soccer and SoccerPlayerDetection dataset
#

import argparse
import pickle
import os
import shutil

import numpy as np
import torch
from torch import optim
import tqdm

from data.data_reader import make_dataloaders
from misc.config import Params
from misc import utils
from network import footandball
from network.ssd_loss import SSDLoss

TRAIN_DIR = os.path.expandvars("${REPO}/runs/train")


def train_model(model: footandball.FootAndBall, **kwargs):
    """
    Performs model training.

    Parameters
    ----------
    model : FootAndBall
        DNN model to be trained
    optimizer : torch.optim
        torch optimizer
    scheduler : torch.optim.lr_scheduler
        torch scheduler
    num_epochs : int
        number of training epochs
    dataloaders : dict[str, torch.utils.data.DataLoader]
    device : torch.device
        {CPU,GPU}
    run_dir : str
        Directory for saving output generated by the training
    """

    # Weight for components of the loss function.
    # Ball-related loss and player-related loss are mean losses (loss per one positive example)
    alpha_l_player = 0.01
    alpha_c_player = 1.0
    alpha_c_ball = 5.0

    # Normalize weights
    total = alpha_l_player + alpha_c_player + alpha_c_ball
    alpha_l_player /= total
    alpha_c_player /= total
    alpha_c_ball /= total

    # Loss function
    criterion = SSDLoss(neg_pos_ratio=3)

    is_validation_set = "val" in kwargs["dataloaders"]
    if is_validation_set:
        phases = ["train", "val"]
    else:
        phases = ["train"]

    # Training statistics
    training_stats = {"train": [], "val": []}

    print("Training...")
    for _ in tqdm.tqdm(range(kwargs["num_epochs"])):
        # Each epoch has a training and validation phase
        # for phase in ['train', 'val']:
        for phase in phases:
            if phase == "train":
                model.train()  # Set model to training mode
            else:
                model.eval()  # Set model to evaluate mode

            batch_stats = {
                "loss": [],
                "loss_ball_c": [],
                "loss_player_c": [],
                "loss_player_l": [],
            }

            count_batches = 0
            # Iterate over data.
            for _, (images, boxes, labels) in enumerate(kwargs["dataloaders"][phase]):
                images = images.to(kwargs["device"])
                h, w = images.shape[-2], images.shape[-1]
                gt_maps = model.groundtruth_maps(boxes, labels, (h, w))
                gt_maps = [e.to(kwargs["device"]) for e in gt_maps]
                count_batches += 1

                with torch.set_grad_enabled(phase == "train"):
                    predictions = model(images)
                    # Backpropagation
                    kwargs["optimizer"].zero_grad()
                    loss_l_player, loss_c_player, loss_c_ball = criterion(
                        predictions, gt_maps
                    )

                    loss = (
                        alpha_l_player * loss_l_player
                        + alpha_c_player * loss_c_player
                        + alpha_c_ball * loss_c_ball
                    )

                    # backward + optimize only if in training phase
                    if phase == "train":
                        loss.backward()
                        kwargs["optimizer"].step()

                # statistics
                count_batches += 1
                batch_stats["loss"].append(loss.item())
                batch_stats["loss_ball_c"].append(loss_c_ball.item())
                batch_stats["loss_player_c"].append(loss_c_player.item())
                batch_stats["loss_player_l"].append(loss_l_player.item())

            # Average stats per batch
            avg_batch_stats = {}
            for e, _ in batch_stats.items():
                avg_batch_stats[e] = np.mean(batch_stats[e])

            training_stats[phase].append(avg_batch_stats)
            s = "{} Avg. loss total / ball conf. / player conf. / player loc.: {:.4f} / {:.4f} / {:.4f} / {:.4f}"
            print(
                s.format(
                    phase,
                    avg_batch_stats["loss"],
                    avg_batch_stats["loss_ball_c"],
                    avg_batch_stats["loss_player_c"],
                    avg_batch_stats["loss_player_l"],
                )
            )

        # Scheduler step
        kwargs["scheduler"].step()
        print("")

    model_filepath = os.path.join(kwargs["run_dir"], "model.pth")
    torch.save(model.state_dict(), model_filepath)

    with open(
        f"{run_dir}/training_stats.pickle",
        "wb",
    ) as handle:
        pickle.dump(training_stats, handle, protocol=pickle.HIGHEST_PROTOCOL)

    return training_stats


def train(params: Params, run_dir: str):
    """
    Wrapper function for model training.
    Sets torch defice, initializes the model, optimizer and scheduler.
    Then starts model training.
    """

    dataloaders = make_dataloaders(params)

    print(f"Training set: Dataset size: {len(dataloaders['train'].dataset)}")
    if "val" in dataloaders:
        print(f"Validation set: Dataset size: {len(dataloaders['val'].dataset)}")

    # Create model
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = footandball.model_factory(params.model, "train")
    model.print_summary(show_architecture=True)
    model = model.to(device)

    optimizer = optim.Adam(model.parameters(), lr=params.lr)
    scheduler_milestones = [int(params.epochs * 0.75)]
    scheduler = torch.optim.lr_scheduler.MultiStepLR(
        optimizer, scheduler_milestones, gamma=0.1
    )
    train_model(
        model,
        **dict(
            optimizer=optimizer,
            scheduler=scheduler,
            num_epochs=params.epochs,
            dataloaders=dataloaders,
            device=device,
            run_dir=run_dir,
        ),
    )


if __name__ == "__main__":
    print("Train FoootAndBall detector on ISSIA dataset")

    if not "DATA_PATH" in os.environ:
        raise EnvironmentError("missing DATA_PATH environmental variable")

    if "REPO" not in os.environ:
        raise EnvironmentError("missing REPO environmental variable")

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--config",
        help="Path to the configuration file",
        type=str,
        default="config.txt",
    )
    parser.add_argument("--debug", dest="debug", help="debug mode", action="store_true")
    parser.add_argument(
        "--run-dir",
        help="[Optional] Directory for saving training data; default: YYMMDD_HHMM",
        required=False,
        default=utils.get_current_time(),
    )
    args = parser.parse_args()

    print(f"Config path: {args.config}")
    print(f"Debug mode: {args.debug}")
    print(f"Run directory: {args.run_dir}")

    # general run history directory
    if not os.path.exists(TRAIN_DIR):
        os.makedirs(TRAIN_DIR)

    # run specific history directory
    run_dir = f"{TRAIN_DIR}/{args.run_dir}"
    if not os.path.exists(run_dir):
        os.mkdir(run_dir)

    shutil.copy(args.config, os.path.join(run_dir, "config.txt"))

    params = Params(args.config)
    params.print()

    train(params, run_dir)


"""
NOTES:
In camera 5 some of the player bboxes are moved by a few pixels from the true position.
When evaluating mean precision use smaller IoU ratio, otherwise detection results are poor.
Alternatively add some margin to ISSIA ground truth bboxes.
"""
